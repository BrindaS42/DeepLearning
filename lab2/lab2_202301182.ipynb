{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-uRN1OFpCHj",
        "outputId": "4de8db2d-646f-4198-b33a-2051d0743f32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b715f733ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import mean_squared_error, f1_score, hamming_loss, jaccard_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"movies.csv\")\n",
        "\n",
        "allowed_cols = [\n",
        "    \"overview\",\n",
        "    \"tagline\",\n",
        "    \"keywords\",\n",
        "    \"genres\",\n",
        "    \"vote_average\"\n",
        "]\n",
        "\n",
        "df = df[allowed_cols].dropna()\n",
        "df.rename(columns={\"vote_average\": \"voting_average\"}, inplace=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "S93onxUptMdS",
        "outputId": "38f002a2-cde5-47aa-83fc-034bc1628295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            overview  \\\n",
              "0  In the 22nd century, a paraplegic Marine is di...   \n",
              "1  Captain Barbossa, long believed to be dead, ha...   \n",
              "2  A cryptic message from Bond’s past sends him o...   \n",
              "3  Following the death of District Attorney Harve...   \n",
              "4  John Carter is a war-weary, former military ca...   \n",
              "\n",
              "                                          tagline  \\\n",
              "0                     Enter the World of Pandora.   \n",
              "1  At the end of the world, the adventure begins.   \n",
              "2                           A Plan No One Escapes   \n",
              "3                                 The Legend Ends   \n",
              "4            Lost in our world, found in another.   \n",
              "\n",
              "                                            keywords  \\\n",
              "0  culture clash future space war space colony so...   \n",
              "1  ocean drug abuse exotic island east india trad...   \n",
              "2         spy based on novel secret agent sequel mi6   \n",
              "3  dc comics crime fighter terrorist secret ident...   \n",
              "4  based on novel mars medallion space travel pri...   \n",
              "\n",
              "                                     genres  voting_average  \n",
              "0  Action Adventure Fantasy Science Fiction             7.2  \n",
              "1                  Adventure Fantasy Action             6.9  \n",
              "2                    Action Adventure Crime             6.3  \n",
              "3               Action Crime Drama Thriller             7.6  \n",
              "4          Action Adventure Science Fiction             6.1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0326627-3e14-4012-a108-ec85d28d5275\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overview</th>\n",
              "      <th>tagline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>genres</th>\n",
              "      <th>voting_average</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
              "      <td>Enter the World of Pandora.</td>\n",
              "      <td>culture clash future space war space colony so...</td>\n",
              "      <td>Action Adventure Fantasy Science Fiction</td>\n",
              "      <td>7.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
              "      <td>At the end of the world, the adventure begins.</td>\n",
              "      <td>ocean drug abuse exotic island east india trad...</td>\n",
              "      <td>Adventure Fantasy Action</td>\n",
              "      <td>6.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
              "      <td>A Plan No One Escapes</td>\n",
              "      <td>spy based on novel secret agent sequel mi6</td>\n",
              "      <td>Action Adventure Crime</td>\n",
              "      <td>6.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Following the death of District Attorney Harve...</td>\n",
              "      <td>The Legend Ends</td>\n",
              "      <td>dc comics crime fighter terrorist secret ident...</td>\n",
              "      <td>Action Crime Drama Thriller</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>John Carter is a war-weary, former military ca...</td>\n",
              "      <td>Lost in our world, found in another.</td>\n",
              "      <td>based on novel mars medallion space travel pri...</td>\n",
              "      <td>Action Adventure Science Fiction</td>\n",
              "      <td>6.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0326627-3e14-4012-a108-ec85d28d5275')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f0326627-3e14-4012-a108-ec85d28d5275 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f0326627-3e14-4012-a108-ec85d28d5275');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3759,\n  \"fields\": [\n    {\n      \"column\": \"overview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3759,\n        \"samples\": [\n          \"A former Prohibition-era Jewish gangster returns to the Lower East Side of Manhattan over thirty years later, where he once again must confront the ghosts and regrets of his old life.\",\n          \"A sleazy cable-TV programmer begins to see his life and the future of media spin out of control in a very unusual fashion when he acquires a new kind of programming for his station.\",\n          \"Jack Harper is one of the last few drone repairmen stationed on Earth.  Part of a massive operation to extract vital resources after decades of war with a terrifying threat known as the Scavs, Jack\\u2019s mission is nearly complete.  His existence is brought crashing down when he rescues a beautiful  stranger from a downed spacecraft.  Her arrival triggers a chain of events that  forces him to question everything he knows and puts the fate of humanity in his hands.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tagline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3745,\n        \"samples\": [\n          \"There's a fine line between love and obsession.\",\n          \"The brothers-in-law are back\",\n          \"Check your pulse at the door... if you have one.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3672,\n        \"samples\": [\n          \"wolf suspicion little red riding hood investigation burglary\",\n          \"cat photographer nightmare hallucination hypnosis\",\n          \"serial killer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1024,\n        \"samples\": [\n          \"Comedy Western\",\n          \"Family Fantasy Science Fiction Adventure\",\n          \"Drama Comedy Family\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"voting_average\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.932246370713526,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          2.9,\n          2.7,\n          7.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "lJAbZjOavZnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    text = text.strip()\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged = pos_tag(tokens)\n",
        "\n",
        "    lemmatized_tokens = [\n",
        "        lemmatizer.lemmatize(word, get_wordnet_pos(tag))\n",
        "        for word, tag in tagged\n",
        "    ]\n",
        "\n",
        "    return \" \".join(lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f0hvFJitV3D",
        "outputId": "be5b3d3a-d9ae-465d-c7b8-539b1d506cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in [\"overview\", \"tagline\", \"keywords\"]:\n",
        "    df[col] = df[col].astype(str).apply(clean_text)"
      ],
      "metadata": {
        "id": "q2dzAEAGvXTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"genres\"] = df[\"genres\"].astype(str).apply(lambda x: x.split())\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "Y_genre = mlb.fit_transform(df[\"genres\"])\n",
        "\n",
        "print(\"Number of genres:\", len(mlb.classes_))\n",
        "print(\"Genres:\", mlb.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsFgq-cdxQXu",
        "outputId": "dedf8d72-73a4-49b7-8090-93f5581c64c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of genres: 22\n",
            "Genres: ['Action' 'Adventure' 'Animation' 'Comedy' 'Crime' 'Documentary' 'Drama'\n",
            " 'Family' 'Fantasy' 'Fiction' 'Foreign' 'History' 'Horror' 'Movie' 'Music'\n",
            " 'Mystery' 'Romance' 'Science' 'TV' 'Thriller' 'War' 'Western']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"genres\"].iloc[0])\n",
        "print(Y_genre[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1s1CNZgx6F1",
        "outputId": "f24321c8-d847-4b76-9c20-a68a81ad731f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Action', 'Adventure', 'Fantasy', 'Science', 'Fiction']\n",
            "[1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "vkKqjKlyxF89",
        "outputId": "888f063b-2858-4248-8c96-d9be34be9bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            overview  \\\n",
              "0  in the nd century a paraplegic marine be dispa...   \n",
              "1  captain barbossa long believe to be dead have ...   \n",
              "2  a cryptic message from bond ’ s past sends him...   \n",
              "3  follow the death of district attorney harvey d...   \n",
              "4  john carter be a warweary former military capt...   \n",
              "\n",
              "                                       tagline  \\\n",
              "0                   enter the world of pandora   \n",
              "1  at the end of the world the adventure begin   \n",
              "2                         a plan no one escape   \n",
              "3                               the legend end   \n",
              "4            lose in our world find in another   \n",
              "\n",
              "                                            keywords  \\\n",
              "0  culture clash future space war space colony so...   \n",
              "1  ocean drug abuse exotic island east india trad...   \n",
              "2           spy base on novel secret agent sequel mi   \n",
              "3  dc comic crime fighter terrorist secret identi...   \n",
              "4  base on novel mar medallion space travel princess   \n",
              "\n",
              "                                           genres  voting_average  \n",
              "0  [Action, Adventure, Fantasy, Science, Fiction]             7.2  \n",
              "1                    [Adventure, Fantasy, Action]             6.9  \n",
              "2                      [Action, Adventure, Crime]             6.3  \n",
              "3                [Action, Crime, Drama, Thriller]             7.6  \n",
              "4           [Action, Adventure, Science, Fiction]             6.1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78464fbb-1cb9-414f-9fd9-a17451b802f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overview</th>\n",
              "      <th>tagline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>genres</th>\n",
              "      <th>voting_average</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in the nd century a paraplegic marine be dispa...</td>\n",
              "      <td>enter the world of pandora</td>\n",
              "      <td>culture clash future space war space colony so...</td>\n",
              "      <td>[Action, Adventure, Fantasy, Science, Fiction]</td>\n",
              "      <td>7.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>captain barbossa long believe to be dead have ...</td>\n",
              "      <td>at the end of the world the adventure begin</td>\n",
              "      <td>ocean drug abuse exotic island east india trad...</td>\n",
              "      <td>[Adventure, Fantasy, Action]</td>\n",
              "      <td>6.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a cryptic message from bond ’ s past sends him...</td>\n",
              "      <td>a plan no one escape</td>\n",
              "      <td>spy base on novel secret agent sequel mi</td>\n",
              "      <td>[Action, Adventure, Crime]</td>\n",
              "      <td>6.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>follow the death of district attorney harvey d...</td>\n",
              "      <td>the legend end</td>\n",
              "      <td>dc comic crime fighter terrorist secret identi...</td>\n",
              "      <td>[Action, Crime, Drama, Thriller]</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>john carter be a warweary former military capt...</td>\n",
              "      <td>lose in our world find in another</td>\n",
              "      <td>base on novel mar medallion space travel princess</td>\n",
              "      <td>[Action, Adventure, Science, Fiction]</td>\n",
              "      <td>6.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78464fbb-1cb9-414f-9fd9-a17451b802f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78464fbb-1cb9-414f-9fd9-a17451b802f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78464fbb-1cb9-414f-9fd9-a17451b802f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3759,\n  \"fields\": [\n    {\n      \"column\": \"overview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3759,\n        \"samples\": [\n          \"a former prohibitionera jewish gangster return to the low east side of manhattan over thirty year later where he once again must confront the ghost and regret of his old life\",\n          \"a sleazy cabletv programmer begin to see his life and the future of medium spin out of control in a very unusual fashion when he acquire a new kind of program for his station\",\n          \"jack harper be one of the last few drone repairman station on earth part of a massive operation to extract vital resource after decade of war with a terrifying threat know a the scavs jack \\u2019 s mission be nearly complete his existence be bring crash down when he rescue a beautiful stranger from a downed spacecraft her arrival trigger a chain of event that force him to question everything he know and put the fate of humanity in his hand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tagline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3727,\n        \"samples\": [\n          \"a letter from john lennon change his life\",\n          \"they kill his wife ten year ago there still time to save her murder be forever until now\",\n          \"evil just mess with the wrong hillbilly\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3672,\n        \"samples\": [\n          \"wolf suspicion little red rid hood investigation burglary\",\n          \"cat photographer nightmare hallucination hypnosis\",\n          \"serial killer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"voting_average\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.932246370713526,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          2.9,\n          2.7,\n          7.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp, g_train, g_temp = train_test_split(\n",
        "    df, df[\"voting_average\"], Y_genre,\n",
        "    test_size=0.30,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test, g_val, g_test = train_test_split(\n",
        "    X_temp, y_temp, g_temp,\n",
        "    test_size=0.50,\n",
        "    random_state=SEED\n",
        ")"
      ],
      "metadata": {
        "id": "9ZFAV9gCySwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading GlovVe"
      ],
      "metadata": {
        "id": "j1ESEWXiyUq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_DIM = 100\n",
        "\n",
        "zip_path = f\"glove.2024.wikigiga.{EMBED_DIM}d.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(\"glove\")\n",
        "\n",
        "glove_file = [f for f in os.listdir(\"glove\") if f.endswith(\".txt\")][0]\n",
        "\n",
        "embeddings = {}\n",
        "with open(os.path.join(\"glove\", glove_file), encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        if not values:\n",
        "            continue\n",
        "\n",
        "        word = values[0]\n",
        "        try:\n",
        "            vector = np.asarray(values[1:], dtype=\"float32\")\n",
        "            if len(vector) == EMBED_DIM:\n",
        "                embeddings[word] = vector\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "print(\"Loaded GloVe vectors:\", len(embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqinBRKcyoNG",
        "outputId": "5197c753-60ce-44a7-ba1e-1cb860ac8f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded GloVe vectors: 1287614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF weighting\n"
      ],
      "metadata": {
        "id": "DAfCBEcByuQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_doc_embeddings(texts, embeddings, embed_dim):\n",
        "    tfidf = TfidfVectorizer(min_df=3)\n",
        "    tfidf_matrix = tfidf.fit_transform(texts)\n",
        "    vocab = tfidf.vocabulary_\n",
        "\n",
        "    covered = sum(1 for w in vocab if w in embeddings)\n",
        "    coverage = covered / len(vocab)\n",
        "    print(f\"Embedding coverage: {coverage:.2%}\")\n",
        "\n",
        "    doc_embeddings = []\n",
        "\n",
        "    for i in range(tfidf_matrix.shape[0]):\n",
        "        row = tfidf_matrix[i]\n",
        "        weighted_vec = np.zeros(embed_dim)\n",
        "        weight_sum = 0\n",
        "\n",
        "        for word, idx in vocab.items():\n",
        "            if word in embeddings:\n",
        "                weight = row[0, idx]\n",
        "                weighted_vec += weight * embeddings[word]\n",
        "                weight_sum += weight\n",
        "\n",
        "        if weight_sum != 0:\n",
        "            weighted_vec /= weight_sum\n",
        "\n",
        "        doc_embeddings.append(weighted_vec)\n",
        "\n",
        "    return np.array(doc_embeddings)"
      ],
      "metadata": {
        "id": "Pt5mS3QDzLjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4910d296",
        "outputId": "6dd7f849-c26d-43e7-88fc-004e6ba8d779"
      },
      "source": [
        "print(\"\\n--- Generating TF-IDF Weighted GloVe Embeddings ---\\n\")\n",
        "\n",
        "X_train_tfidf_overview = build_doc_embeddings(X_train[\"overview\"], embeddings, EMBED_DIM)\n",
        "X_val_tfidf_overview = build_doc_embeddings(X_val[\"overview\"], embeddings, EMBED_DIM)\n",
        "X_test_tfidf_overview = build_doc_embeddings(X_test[\"overview\"], embeddings, EMBED_DIM)\n",
        "\n",
        "X_train_tfidf_tagline = build_doc_embeddings(X_train[\"tagline\"], embeddings, EMBED_DIM)\n",
        "X_val_tfidf_tagline = build_doc_embeddings(X_val[\"tagline\"], embeddings, EMBED_DIM)\n",
        "X_test_tfidf_tagline = build_doc_embeddings(X_test[\"tagline\"], embeddings, EMBED_DIM)\n",
        "\n",
        "X_train_tfidf_keywords = build_doc_embeddings(X_train[\"keywords\"], embeddings, EMBED_DIM)\n",
        "X_val_tfidf_keywords = build_doc_embeddings(X_val[\"keywords\"], embeddings, EMBED_DIM)\n",
        "X_test_tfidf_keywords = build_doc_embeddings(X_test[\"keywords\"], embeddings, EMBED_DIM)\n",
        "\n",
        "X_train_tfidf = np.concatenate([X_train_tfidf_overview, X_train_tfidf_tagline, X_train_tfidf_keywords], axis=1)\n",
        "X_val_tfidf = np.concatenate([X_val_tfidf_overview, X_val_tfidf_tagline, X_val_tfidf_keywords], axis=1)\n",
        "X_test_tfidf = np.concatenate([X_test_tfidf_overview, X_test_tfidf_tagline, X_test_tfidf_keywords], axis=1)\n",
        "\n",
        "print(\"TF-IDF weighted GloVe embeddings generated successfully.\")\n",
        "print(f\"X_train_tfidf shape: {X_train_tfidf.shape}\")\n",
        "print(f\"X_val_tfidf shape: {X_val_tfidf.shape}\")\n",
        "print(f\"X_test_tfidf shape: {X_test_tfidf.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating TF-IDF Weighted GloVe Embeddings ---\n",
            "\n",
            "Embedding coverage: 99.05%\n",
            "Embedding coverage: 99.65%\n",
            "Embedding coverage: 99.64%\n",
            "Embedding coverage: 99.39%\n",
            "Embedding coverage: 98.96%\n",
            "Embedding coverage: 98.63%\n",
            "Embedding coverage: 98.83%\n",
            "Embedding coverage: 99.10%\n",
            "Embedding coverage: 99.07%\n",
            "TF-IDF weighted GloVe embeddings generated successfully.\n",
            "X_train_tfidf shape: (2631, 300)\n",
            "X_val_tfidf shape: (564, 300)\n",
            "X_test_tfidf shape: (564, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_doc_embeddings_glove_only(texts, embeddings, embed_dim):\n",
        "    doc_embeddings = []\n",
        "\n",
        "    for text in texts:\n",
        "        words = text.split()\n",
        "        vectors = [embeddings[w] for w in words if w in embeddings]\n",
        "\n",
        "        if len(vectors) == 0:\n",
        "            doc_embeddings.append(np.zeros(embed_dim))\n",
        "        else:\n",
        "            doc_embeddings.append(np.mean(vectors, axis=0))\n",
        "\n",
        "    return np.array(doc_embeddings)"
      ],
      "metadata": {
        "id": "6ASFN5Xv1K4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f050bd73",
        "outputId": "067bf5d9-c120-4e95-e16d-d81fdb71f331"
      },
      "source": [
        "print(\"\\n--- Generating GloVe Only Embeddings ---\\n\")\n",
        "\n",
        "X_train_glove_overview = build_doc_embeddings_glove_only(X_train[\"overview\"], embeddings, EMBED_DIM)\n",
        "X_val_glove_overview = build_doc_embeddings_glove_only(X_val[\"overview\"], embeddings, EMBED_DIM)\n",
        "X_test_glove_overview = build_doc_embeddings_glove_only(X_test[\"overview\"], embeddings, EMBED_DIM)\n",
        "\n",
        "X_train_glove_tagline = build_doc_embeddings_glove_only(X_train[\"tagline\"], embeddings, EMBED_DIM)\n",
        "X_val_glove_tagline = build_doc_embeddings_glove_only(X_val[\"tagline\"], embeddings, EMBED_DIM)\n",
        "X_test_glove_tagline = build_doc_embeddings_glove_only(X_test[\"tagline\"], embeddings, EMBED_DIM)\n",
        "\n",
        "X_train_glove_keywords = build_doc_embeddings_glove_only(X_train[\"keywords\"], embeddings, EMBED_DIM)\n",
        "X_val_glove_keywords = build_doc_embeddings_glove_only(X_val[\"keywords\"], embeddings, EMBED_DIM)\n",
        "X_test_glove_keywords = build_doc_embeddings_glove_only(X_test[\"keywords\"], embeddings, EMBED_DIM)\n",
        "\n",
        "X_train_glove = np.concatenate([X_train_glove_overview, X_train_glove_tagline, X_train_glove_keywords], axis=1)\n",
        "X_val_glove = np.concatenate([X_val_glove_overview, X_val_glove_tagline, X_val_glove_keywords], axis=1)\n",
        "X_test_glove = np.concatenate([X_test_glove_overview, X_test_glove_tagline, X_test_glove_keywords], axis=1)\n",
        "\n",
        "print(\"GloVe-only embeddings generated successfully.\")\n",
        "print(f\"X_train_glove shape: {X_train_glove.shape}\")\n",
        "print(f\"X_val_glove shape: {X_val_glove.shape}\")\n",
        "print(f\"X_test_glove shape: {X_test_glove.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating GloVe Only Embeddings ---\n",
            "\n",
            "GloVe-only embeddings generated successfully.\n",
            "X_train_glove shape: (2631, 300)\n",
            "X_val_glove shape: (564, 300)\n",
            "X_test_glove shape: (564, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regressor"
      ],
      "metadata": {
        "id": "M5DRAVw-zbZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RatingRegressor(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze()"
      ],
      "metadata": {
        "id": "rjIgmfvUza3a"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_regressor(X_train, y_train, X_test, y_test):\n",
        "    model = RatingRegressor(X_train.shape[1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "    for epoch in range(30):\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(X_train)\n",
        "        loss = loss_fn(preds, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_test)\n",
        "        mse = mean_squared_error(y_test.numpy(), preds.numpy())\n",
        "        rmse = np.sqrt(mse)\n",
        "\n",
        "    return mse, rmse"
      ],
      "metadata": {
        "id": "2kFAgVo_zoMj"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6a9308c",
        "outputId": "c7fc33ba-a4a0-47d1-e414-b3856cbc0f1c"
      },
      "source": [
        "print(\"\\n--- Calculating Regression Baseline (Global Mean Rating) ---\\n\")\n",
        "\n",
        "global_mean_rating = y_train.mean()\n",
        "\n",
        "baseline_preds_val = np.full_like(y_val, global_mean_rating)\n",
        "\n",
        "baseline_mse_val = mean_squared_error(y_val, baseline_preds_val)\n",
        "baseline_rmse_val = np.sqrt(baseline_mse_val)\n",
        "\n",
        "print(\"Regression Baseline Results (Global Mean Rating on Validation Set):\")\n",
        "print(f\"  Global Mean Rating (from training data): {global_mean_rating:.4f}\")\n",
        "print(f\"  Baseline MSE (Validation): {baseline_mse_val:.4f}\")\n",
        "print(f\"  Baseline RMSE (Validation): {baseline_rmse_val:.4f}\")\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Calculating Regression Baseline (Global Mean Rating) ---\n",
            "\n",
            "Regression Baseline Results (Global Mean Rating on Validation Set):\n",
            "  Global Mean Rating (from training data): 6.2339\n",
            "  Baseline MSE (Validation): 0.7780\n",
            "  Baseline RMSE (Validation): 0.8820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Glove only\n"
      ],
      "metadata": {
        "id": "I9FfmziiCbQM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8616792",
        "outputId": "b02900b8-f4ed-4d50-87cf-5487806abdcc"
      },
      "source": [
        "\n",
        "mse_ov, rmse_ov = train_regressor(\n",
        "    X_train_glove_overview, y_train, X_test_glove_overview, y_test\n",
        ")\n",
        "\n",
        "print(\"Overview only:\")\n",
        "print(f\"MSE: {mse_ov:.4f}, RMSE: {rmse_ov:.4f}\")\n",
        "\n",
        "mse_tg, rmse_tg = train_regressor(\n",
        "    X_train_glove_tagline, y_train, X_test_glove_tagline, y_test\n",
        ")\n",
        "\n",
        "print(\"Tagline only:\")\n",
        "print(f\"MSE: {mse_tg:.4f}, RMSE: {rmse_tg:.4f}\")\n",
        "\n",
        "\n",
        "mse_kw, rmse_kw = train_regressor(\n",
        "    X_train_glove_keywords, y_train, X_test_glove_keywords, y_test\n",
        ")\n",
        "\n",
        "print(\"Keywords only:\")\n",
        "print(f\"MSE: {mse_kw:.4f}, RMSE: {rmse_kw:.4f}\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overview only:\n",
            "MSE: 5.6593, RMSE: 2.3789\n",
            "Tagline only:\n",
            "MSE: 3.2568, RMSE: 1.8047\n",
            "Keywords only:\n",
            "MSE: 7.5196, RMSE: 2.7422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With TFIDG weighting\n"
      ],
      "metadata": {
        "id": "9Q9g13VACgFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Regression: Overview (TF-IDF + GloVe) ---\\n\")\n",
        "\n",
        "mse_ov, rmse_ov = train_regressor(\n",
        "    X_train_tfidf_overview, y_train,\n",
        "    X_test_tfidf_overview, y_test\n",
        ")\n",
        "\n",
        "print(f\"Overview -> MSE: {mse_ov:.4f}, RMSE: {rmse_ov:.4f}\")\n",
        "\n",
        "print(\"\\n--- Regression: Tagline (TF-IDF + GloVe) ---\\n\")\n",
        "\n",
        "mse_tg, rmse_tg = train_regressor(\n",
        "    X_train_tfidf_tagline, y_train,\n",
        "    X_test_tfidf_tagline, y_test\n",
        ")\n",
        "\n",
        "print(f\"Tagline -> MSE: {mse_tg:.4f}, RMSE: {rmse_tg:.4f}\")\n",
        "\n",
        "print(\"\\n--- Regression: Keywords (TF-IDF + GloVe) ---\\n\")\n",
        "\n",
        "mse_kw, rmse_kw = train_regressor(\n",
        "    X_train_tfidf_keywords, y_train,\n",
        "    X_test_tfidf_keywords, y_test\n",
        ")\n",
        "\n",
        "print(f\"Keywords -> MSE: {mse_kw:.4f}, RMSE: {rmse_kw:.4f}\")"
      ],
      "metadata": {
        "id": "zX4PawB-FeqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d341faca-d3fa-4f36-bad5-6f5851b95616"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Regression: Overview (TF-IDF + GloVe) ---\n",
            "\n",
            "Overview -> MSE: 5.9614, RMSE: 2.4416\n",
            "\n",
            "--- Regression: Tagline (TF-IDF + GloVe) ---\n",
            "\n",
            "Tagline -> MSE: 3.0571, RMSE: 1.7484\n",
            "\n",
            "--- Regression: Keywords (TF-IDF + GloVe) ---\n",
            "\n",
            "Keywords -> MSE: 6.7466, RMSE: 2.5974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifier"
      ],
      "metadata": {
        "id": "_jsmzd1Mzp95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenreClassifier(nn.Module):\n",
        "    def __init__(self, dim, num_labels):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "3idqgu8nzsU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_genre_classifier(X_tr, y_tr, X_te, y_te):\n",
        "    model = GenreClassifier(X_tr.shape[1], y_tr.shape[1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    X_tr = torch.tensor(X_tr, dtype=torch.float32)\n",
        "    y_tr = torch.tensor(y_tr, dtype=torch.float32)\n",
        "    X_te = torch.tensor(X_te, dtype=torch.float32)\n",
        "\n",
        "    print(\"\\nStarting Classifier Training...\")\n",
        "    for epoch in range(30):\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(X_tr)\n",
        "        loss = loss_fn(logits, y_tr)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            print(f\"  Epoch {epoch+1:2d}/30, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    preds = torch.sigmoid(model(X_te)).detach().numpy() > 0.5\n",
        "\n",
        "    micro = f1_score(y_te, preds, average=\"micro\")\n",
        "    macro = f1_score(y_te, preds, average=\"macro\")\n",
        "    hamming = hamming_loss(y_te, preds)\n",
        "    jaccard = jaccard_score(y_te, preds, average=\"samples\")\n",
        "\n",
        "    return micro, macro, hamming, jaccard"
      ],
      "metadata": {
        "id": "Rsd24em_zw_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "816b5ee4",
        "outputId": "b110242b-7750-4adf-fd63-3304dd8bb71b"
      },
      "source": [
        "print(\"\\n--- Genre Classification: Overview (GloVe Only) ---\\n\")\n",
        "\n",
        "micro_ov_g, macro_ov_g, hamming_ov_g, jaccard_ov_g = train_genre_classifier(\n",
        "    X_train_glove_overview, g_train,\n",
        "    X_test_glove_overview, g_test\n",
        ")\n",
        "\n",
        "print(\"Overview Results (GloVe Only):\")\n",
        "print(f\"  F1 Micro    : {micro_ov_g:.4f}\")\n",
        "print(f\"  F1 Macro    : {macro_ov_g:.4f}\")\n",
        "print(f\"  Hamming Loss: {hamming_ov_g:.4f}\")\n",
        "print(f\"  Jaccard     : {jaccard_ov_g:.4f}\")\n",
        "\n",
        "print(\"\\n--- Genre Classification: Tagline (GloVe Only) ---\\n\")\n",
        "\n",
        "micro_tg_g, macro_tg_g, hamming_tg_g, jaccard_tg_g = train_genre_classifier(\n",
        "    X_train_glove_tagline, g_train,\n",
        "    X_test_glove_tagline, g_test\n",
        ")\n",
        "\n",
        "print(\"Tagline Results (GloVe Only):\")\n",
        "print(f\"  F1 Micro    : {micro_tg_g:.4f}\")\n",
        "print(f\"  F1 Macro    : {macro_tg_g:.4f}\")\n",
        "print(f\"  Hamming Loss: {hamming_tg_g:.4f}\")\n",
        "print(f\"  Jaccard     : {jaccard_tg_g:.4f}\")\n",
        "\n",
        "print(\"\\n--- Genre Classification: Keywords (GloVe Only) ---\\n\")\n",
        "\n",
        "micro_kw_g, macro_kw_g, hamming_kw_g, jaccard_kw_g = train_genre_classifier(\n",
        "    X_train_glove_keywords, g_train,\n",
        "    X_test_glove_keywords, g_test\n",
        ")\n",
        "\n",
        "print(\"Keywords Results (GloVe Only):\")\n",
        "print(f\"  F1 Micro    : {micro_kw_g:.4f}\")\n",
        "print(f\"  F1 Macro    : {macro_kw_g:.4f}\")\n",
        "print(f\"  Hamming Loss: {hamming_kw_g:.4f}\")\n",
        "print(f\"  Jaccard     : {jaccard_kw_g:.4f}\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Genre Classification: Overview (GloVe Only) ---\n",
            "\n",
            "\n",
            "Starting Classifier Training...\n",
            "  Epoch  1/30, Loss: 0.6978\n",
            "  Epoch  5/30, Loss: 0.6387\n",
            "  Epoch 10/30, Loss: 0.5642\n",
            "  Epoch 15/30, Loss: 0.4840\n",
            "  Epoch 20/30, Loss: 0.4091\n",
            "  Epoch 25/30, Loss: 0.3568\n",
            "  Epoch 30/30, Loss: 0.3314\n",
            "Overview Results (GloVe Only):\n",
            "  F1 Micro    : 0.0026\n",
            "  F1 Macro    : 0.0007\n",
            "  Hamming Loss: 0.1256\n",
            "  Jaccard     : 0.0027\n",
            "\n",
            "--- Genre Classification: Tagline (GloVe Only) ---\n",
            "\n",
            "\n",
            "Starting Classifier Training...\n",
            "  Epoch  1/30, Loss: 0.7025\n",
            "  Epoch  5/30, Loss: 0.6334\n",
            "  Epoch 10/30, Loss: 0.5428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 15/30, Loss: 0.4493\n",
            "  Epoch 20/30, Loss: 0.3751\n",
            "  Epoch 25/30, Loss: 0.3382\n",
            "  Epoch 30/30, Loss: 0.3273\n",
            "Tagline Results (GloVe Only):\n",
            "  F1 Micro    : 0.0728\n",
            "  F1 Macro    : 0.0162\n",
            "  Hamming Loss: 0.1231\n",
            "  Jaccard     : 0.0552\n",
            "\n",
            "--- Genre Classification: Keywords (GloVe Only) ---\n",
            "\n",
            "\n",
            "Starting Classifier Training...\n",
            "  Epoch  1/30, Loss: 0.7028\n",
            "  Epoch  5/30, Loss: 0.6387\n",
            "  Epoch 10/30, Loss: 0.5566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 15/30, Loss: 0.4703\n",
            "  Epoch 20/30, Loss: 0.3944\n",
            "  Epoch 25/30, Loss: 0.3467\n",
            "  Epoch 30/30, Loss: 0.3262\n",
            "Keywords Results (GloVe Only):\n",
            "  F1 Micro    : 0.1511\n",
            "  F1 Macro    : 0.0290\n",
            "  Hamming Loss: 0.1205\n",
            "  Jaccard     : 0.1156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0d5de90",
        "outputId": "08306e92-6999-455c-b253-b78812426812"
      },
      "source": [
        "print(\"\\n--- Genre Classification: Overview (TF-IDF + GloVe) ---\\n\")\n",
        "\n",
        "micro_ov, macro_ov, hamming_ov, jaccard_ov = train_genre_classifier(\n",
        "    X_train_tfidf_overview, g_train,\n",
        "    X_test_tfidf_overview, g_test\n",
        ")\n",
        "\n",
        "print(\"Overview Results:\")\n",
        "print(f\"  F1 Micro    : {micro_ov:.4f}\")\n",
        "print(f\"  F1 Macro    : {macro_ov:.4f}\")\n",
        "print(f\"  Hamming Loss: {hamming_ov:.4f}\")\n",
        "print(f\"  Jaccard     : {jaccard_ov:.4f}\")\n",
        "\n",
        "print(\"\\n--- Genre Classification: Tagline (TF-IDF + GloVe) ---\\n\")\n",
        "\n",
        "micro_tg, macro_tg, hamming_tg, jaccard_tg = train_genre_classifier(\n",
        "    X_train_tfidf_tagline, g_train,\n",
        "    X_test_tfidf_tagline, g_test\n",
        ")\n",
        "\n",
        "print(\"Tagline Results:\")\n",
        "print(f\"  F1 Micro    : {micro_tg:.4f}\")\n",
        "print(f\"  F1 Macro    : {macro_tg:.4f}\")\n",
        "print(f\"  Hamming Loss: {hamming_tg:.4f}\")\n",
        "print(f\"  Jaccard     : {jaccard_tg:.4f}\")\n",
        "\n",
        "print(\"\\n--- Genre Classification: Keywords (TF-IDF + GloVe) ---\\n\")\n",
        "\n",
        "micro_kw, macro_kw, hamming_kw, jaccard_kw = train_genre_classifier(\n",
        "    X_train_tfidf_keywords, g_train,\n",
        "    X_test_tfidf_keywords, g_test\n",
        ")\n",
        "\n",
        "print(\"Keywords Results:\")\n",
        "print(f\"  F1 Micro    : {micro_kw:.4f}\")\n",
        "print(f\"  F1 Macro    : {macro_kw:.4f}\")\n",
        "print(f\"  Hamming Loss: {hamming_kw:.4f}\")\n",
        "print(f\"  Jaccard     : {jaccard_kw:.4f}\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Genre Classification: Overview (TF-IDF + GloVe) ---\n",
            "\n",
            "\n",
            "Starting Classifier Training...\n",
            "  Epoch  1/30, Loss: 0.6876\n",
            "  Epoch  5/30, Loss: 0.6354\n",
            "  Epoch 10/30, Loss: 0.5636\n",
            "  Epoch 15/30, Loss: 0.4819\n",
            "  Epoch 20/30, Loss: 0.4044\n",
            "  Epoch 25/30, Loss: 0.3514\n",
            "  Epoch 30/30, Loss: 0.3285\n",
            "Overview Results:\n",
            "  F1 Micro    : 0.0214\n",
            "  F1 Macro    : 0.0055\n",
            "  Hamming Loss: 0.1251\n",
            "  Jaccard     : 0.0158\n",
            "\n",
            "--- Genre Classification: Tagline (TF-IDF + GloVe) ---\n",
            "\n",
            "\n",
            "Starting Classifier Training...\n",
            "  Epoch  1/30, Loss: 0.7038\n",
            "  Epoch  5/30, Loss: 0.6360\n",
            "  Epoch 10/30, Loss: 0.5510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 15/30, Loss: 0.4624\n",
            "  Epoch 20/30, Loss: 0.3885\n",
            "  Epoch 25/30, Loss: 0.3472\n",
            "  Epoch 30/30, Loss: 0.3313\n",
            "Tagline Results:\n",
            "  F1 Micro    : 0.0375\n",
            "  F1 Macro    : 0.0094\n",
            "  Hamming Loss: 0.1240\n",
            "  Jaccard     : 0.0297\n",
            "\n",
            "--- Genre Classification: Keywords (TF-IDF + GloVe) ---\n",
            "\n",
            "\n",
            "Starting Classifier Training...\n",
            "  Epoch  1/30, Loss: 0.6941\n",
            "  Epoch  5/30, Loss: 0.6312\n",
            "  Epoch 10/30, Loss: 0.5489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 15/30, Loss: 0.4619\n",
            "  Epoch 20/30, Loss: 0.3880\n",
            "  Epoch 25/30, Loss: 0.3451\n",
            "  Epoch 30/30, Loss: 0.3275\n",
            "Keywords Results:\n",
            "  F1 Micro    : 0.1676\n",
            "  F1 Macro    : 0.0260\n",
            "  Hamming Loss: 0.1241\n",
            "  Jaccard     : 0.1332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## genre word analysis"
      ],
      "metadata": {
        "id": "8r9OOeZaz8V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "def frequent_words_per_genre(df, text_col, min_freq=3, top_k=10):\n",
        "    results = {}\n",
        "\n",
        "    for genre in mlb.classes_:\n",
        "        texts = df[df[\"genres\"].apply(lambda x: genre in x)][text_col]\n",
        "\n",
        "        counter = Counter()\n",
        "        for text in texts:\n",
        "            counter.update(text.split())\n",
        "\n",
        "        filtered = {w: c for w, c in counter.items() if c >= min_freq}\n",
        "\n",
        "        sorted_words = sorted(filtered.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        top_words = sorted_words[:top_k]\n",
        "        bottom_words = sorted_words[-top_k:]\n",
        "\n",
        "        results[genre] = {\n",
        "            \"top_words\": top_words,\n",
        "            \"bottom_words\": bottom_words\n",
        "        }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "1MQkzFdPz-ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3c0e68e",
        "outputId": "10de7431-0a4a-4602-931f-e193f8b01008"
      },
      "source": [
        "print(\"\\n--- Genre Word Analysis for Overview ---\\n\")\n",
        "overview_genre_analysis = genre_word_analysis(df, \"overview\")\n",
        "for genre, data in overview_genre_analysis.items():\n",
        "    print(f\"Genre: {genre}\")\n",
        "    print(f\"  Top words: {data['top_words']}\")\n",
        "    print(f\"  Bottom words: {data['bottom_words']}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Genre Word Analysis for Overview ---\n",
            "\n",
            "Genre: Action\n",
            "  Top words: ['the' 'to' 'of' 'and' 'be' 'his' 'in' 'on' 'with' 'he']\n",
            "  Bottom words: ['claus' 'cliff' 'clifford' 'clint' 'clique' 'owl' 'participant'\n",
            " 'wellbeing' 'claire' 'claudia']\n",
            "\n",
            "Genre: Adventure\n",
            "  Top words: ['the' 'to' 'and' 'of' 'be' 'his' 'in' 'with' 'on' 'an']\n",
            "  Bottom words: ['crave' 'mama' 'filmed' 'finch' 'creed' 'creepy' 'critic' 'critical'\n",
            " 'crooked' 'crucifixion']\n",
            "\n",
            "Genre: Animation\n",
            "  Top words: ['the' 'and' 'to' 'be' 'of' 'his' 'in' 'he' 'an' 'when']\n",
            "  Bottom words: ['ire' 'slow' 'slip' 'slim' 'slightly' 'slide' 'investor' 'investment'\n",
            " 'investigator' 'irresponsible']\n",
            "\n",
            "Genre: Comedy\n",
            "  Top words: ['the' 'to' 'and' 'be' 'of' 'his' 'in' 'with' 'her' 'he']\n",
            "  Bottom words: ['voorhees' 'maryland' 'powell' 'powerless' 'coerce' 'enforcement'\n",
            " 'enforcer' 'engulf' 'enigmatic' 'vader']\n",
            "\n",
            "Genre: Crime\n",
            "  Top words: ['the' 'to' 'of' 'and' 'his' 'be' 'in' 'he' 'with' 'for']\n",
            "  Bottom words: ['patty' 'fabled' 'facility' 'fade' 'fading' 'failed' 'failure' 'fairy'\n",
            " 'fairytale' 'patrick']\n",
            "\n",
            "Genre: Documentary\n",
            "  Top words: ['the' 'and' 'of' 'documentary' 'in' 'to' 'be' 'film' 'at' 'on']\n",
            "  Bottom words: ['max' 'mechanic' 'mechanical' 'medal' 'medication' 'medicine' 'medieval'\n",
            " 'matthew' 'maturity' 'maverick']\n",
            "\n",
            "Genre: Drama\n",
            "  Top words: ['the' 'to' 'of' 'and' 'his' 'be' 'in' 'her' 'he' 'with']\n",
            "  Bottom words: ['creepy' 'lurks' 'jigsaw' 'jigsaws' 'generate' 'harass' 'oppressive'\n",
            " 'ops' 'intern' 'patty']\n",
            "\n",
            "Genre: Family\n",
            "  Top words: ['the' 'to' 'and' 'of' 'be' 'his' 'in' 'he' 'with' 'an']\n",
            "  Bottom words: ['sale' 'federation' 'federal' 'fearful' 'fiancée' 'fiancé' 'fiancee'\n",
            " 'feud' 'sample' 'samantha']\n",
            "\n",
            "Genre: Fantasy\n",
            "  Top words: ['the' 'to' 'and' 'of' 'be' 'his' 'in' 'he' 'with' 'her']\n",
            "  Bottom words: ['quietly' 'grizzly' 'grows' 'gruesome' 'guess' 'greatly' 'greed' 'greek'\n",
            " 'greg' 'radar']\n",
            "\n",
            "Genre: Fiction\n",
            "  Top words: ['the' 'to' 'of' 'and' 'be' 'in' 'his' 'an' 'with' 'that']\n",
            "  Bottom words: ['evangelist' 'error' 'erotic' 'ernest' 'kingdom' 'erica' 'eric'\n",
            " 'eradicate' 'evelyn' 'kiss']\n",
            "\n",
            "Genre: Foreign\n",
            "  Top words: ['the' 'of' 'with' 'and' 'his' 'film' 'be' 'in' 'detroit' 'he']\n",
            "  Bottom words: ['perilous' 'persuade' 'personality' 'personal' 'persona' 'persian'\n",
            " 'perry' 'permanently' 'permanent' 'perkins']\n",
            "\n",
            "Genre: History\n",
            "  Top words: ['the' 'of' 'in' 'and' 'to' 'his' 'war' 'be' 'story' 'on']\n",
            "  Bottom words: ['island' 'skip' 'skills' 'skilled' 'ireland' 'ire' 'iraqi' 'iranian' 'iq'\n",
            " 'iowa']\n",
            "\n",
            "Genre: Horror\n",
            "  Top words: ['the' 'of' 'to' 'be' 'and' 'her' 'in' 'that' 'with' 'his']\n",
            "  Bottom words: ['foolproof' 'mere' 'surveillance' 'surroundings' 'forget' 'forensic'\n",
            " 'foreman' 'ford' 'forbidden' 'forbid']\n",
            "\n",
            "Genre: Movie\n",
            "  Top words: ['christmas' 'the' 'and' 'brown' 'charlie' 'everyone' 'maneating'\n",
            " 'sharkinfested' 'hurricane' 'tornado']\n",
            "  Bottom words: ['physical' 'pile' 'pig' 'pierre' 'piece' 'picture' 'pick' 'picard'\n",
            " 'piano' 'pi']\n",
            "\n",
            "Genre: Music\n",
            "  Top words: ['the' 'and' 'of' 'to' 'in' 'be' 'his' 'her' 'with' 'on']\n",
            "  Bottom words: ['kat' 'juni' 'junior' 'junkie' 'jury' 'justice' 'kane' 'kangaroo' 'karen'\n",
            " 'jungle']\n",
            "\n",
            "Genre: Mystery\n",
            "  Top words: ['the' 'to' 'be' 'of' 'and' 'in' 'his' 'he' 'that' 'her']\n",
            "  Bottom words: ['harris' 'hapless' 'hawk' 'hawkins' 'hayden' 'hayes' 'hazard' 'haze'\n",
            " 'headline' 'headmaster']\n",
            "\n",
            "Genre: Romance\n",
            "  Top words: ['the' 'to' 'and' 'her' 'be' 'of' 'his' 'in' 'with' 'he']\n",
            "  Bottom words: ['playground' 'diabolical' 'dewey' 'devour' 'devito' 'devise' 'devious'\n",
            " 'device' 'developer' 'devastating']\n",
            "\n",
            "Genre: Science\n",
            "  Top words: ['the' 'to' 'of' 'and' 'be' 'in' 'his' 'an' 'with' 'that']\n",
            "  Bottom words: ['evangelist' 'error' 'erotic' 'ernest' 'kingdom' 'erica' 'eric'\n",
            " 'eradicate' 'evelyn' 'kiss']\n",
            "\n",
            "Genre: TV\n",
            "  Top words: ['christmas' 'the' 'and' 'brown' 'charlie' 'everyone' 'maneating'\n",
            " 'sharkinfested' 'hurricane' 'tornado']\n",
            "  Bottom words: ['physical' 'pile' 'pig' 'pierre' 'piece' 'picture' 'pick' 'picard'\n",
            " 'piano' 'pi']\n",
            "\n",
            "Genre: Thriller\n",
            "  Top words: ['the' 'to' 'of' 'be' 'and' 'his' 'in' 'he' 'her' 'an']\n",
            "  Bottom words: ['claudia' 'wacky' 'voter' 'loyalist' 'loyal' 'lois' 'unsuccessful'\n",
            " 'remind' 'religion' 'climactic']\n",
            "\n",
            "Genre: War\n",
            "  Top words: ['the' 'war' 'of' 'to' 'in' 'be' 'and' 'his' 'during' 'ii']\n",
            "  Bottom words: ['terminator' 'lynn' 'lyric' 'tennis' 'tense' 'tension' 'teri' 'terminal'\n",
            " 'terminate' 'lynch']\n",
            "\n",
            "Genre: Western\n",
            "  Top words: ['the' 'and' 'to' 'of' 'in' 'be' 'his' 'outlaw' 'town' 'their']\n",
            "  Bottom words: ['mitchell' 'missing' 'missionary' 'mist' 'mistake' 'mistaken'\n",
            " 'mistakenly' 'mistress' 'mit' 'mitch']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69b64735",
        "outputId": "2ba1c977-d259-4aa7-c8bc-14c6a1ca8c43"
      },
      "source": [
        "print(\"\\n--- Genre Word Analysis for Tagline ---\\n\")\n",
        "tagline_genre_analysis = genre_word_analysis(df, \"tagline\")\n",
        "for genre, data in tagline_genre_analysis.items():\n",
        "    print(f\"Genre: {genre}\")\n",
        "    print(f\"  Top words: {data['top_words']}\")\n",
        "    print(f\"  Bottom words: {data['bottom_words']}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Genre Word Analysis for Tagline ---\n",
            "\n",
            "Genre: Action\n",
            "  Top words: ['the' 'be' 'of' 'to' 'no' 'have' 'for' 'in' 'it' 'one']\n",
            "  Bottom words: ['page' 'crowd' 'president' 'present' 'possible' 'possibility'\n",
            " 'popularity' 'pop' 'player' 'protection']\n",
            "\n",
            "Genre: Adventure\n",
            "  Top words: ['the' 'be' 'of' 'adventure' 'to' 'it' 'for' 'one' 'have' 'world']\n",
            "  Bottom words: ['promise' 'relationship' 'everyones' 'everywhere' 'except' 'experiment'\n",
            " 'explain' 'explode' 'explosive' 'pretty']\n",
            "\n",
            "Genre: Animation\n",
            "  Top words: ['the' 'be' 'adventure' 'to' 'get' 'it' 'of' 'for' 'little' 'your']\n",
            "  Bottom words: ['suddenly' 'teacher' 'stop' 'storm' 'straight' 'stranger' 'street'\n",
            " 'strength' 'strong' 'student']\n",
            "\n",
            "Genre: Comedy\n",
            "  Top words: ['the' 'be' 'to' 'it' 'get' 'of' 'you' 'in' 'he' 'and']\n",
            "  Bottom words: ['anywhere' 'army' 'unite' 'unspeakable' 'train' 'untold' 'travel'\n",
            " 'temptation' 'era' 'eternity']\n",
            "\n",
            "Genre: Crime\n",
            "  Top words: ['be' 'the' 'you' 'to' 'no' 'in' 'of' 'it' 'get' 'for']\n",
            "  Bottom words: ['princess' 'ruin' 'pick' 'herself' 'help' 'heaven' 'hear' 'heal' 'haunt'\n",
            " 'hat']\n",
            "\n",
            "Genre: Documentary\n",
            "  Top words: ['the' 'of' 'in' 'what' 'for' 'to' 'on' 'film' 'never' 'you']\n",
            "  Bottom words: ['possibility' 'people' 'perfect' 'perfectly' 'period' 'person' 'piece'\n",
            " 'pig' 'plan' 'plane']\n",
            "\n",
            "Genre: Drama\n",
            "  Top words: ['the' 'be' 'of' 'to' 'you' 'it' 'love' 'in' 'and' 'life']\n",
            "  Bottom words: ['agent' 'already' 'zero' 'halloween' 'lot' 'final' 'week' 'wasnt'\n",
            " 'machine' 'lucky']\n",
            "\n",
            "Genre: Family\n",
            "  Top words: ['the' 'be' 'it' 'to' 'adventure' 'of' 'get' 'for' 'world' 'he']\n",
            "  Bottom words: ['jason' 'since' 'sing' 'single' 'huge' 'human' 'hunted' 'hunter' 'hurt'\n",
            " 'james']\n",
            "\n",
            "Genre: Fantasy\n",
            "  Top words: ['the' 'be' 'of' 'it' 'in' 'to' 'you' 'for' 'world' 'your']\n",
            "  Bottom words: ['fish' 'present' 'president' 'frank' 'free' 'freedom' 'friendship'\n",
            " 'frozen' 'full' 'funny']\n",
            "\n",
            "Genre: Fiction\n",
            "  Top words: ['the' 'be' 'to' 'it' 'you' 'have' 'of' 'future' 'in' 'begin']\n",
            "  Bottom words: ['half' 'sexual' 'sexy' 'share' 'government' 'grave' 'greatness' 'grow'\n",
            " 'gun' 'sex']\n",
            "\n",
            "Genre: Foreign\n",
            "  Top words: ['the' 'conquer' 'he' 'of' 'to' 'father' 'paradise' 'promise' 'be' 'call']\n",
            "  Bottom words: ['prisoner' 'pop' 'popularity' 'possibility' 'possible' 'power' 'powerful'\n",
            " 'pray' 'prepare' 'present']\n",
            "\n",
            "Genre: History\n",
            "  Top words: ['the' 'be' 'of' 'man' 'world' 'it' 'in' 'story' 'true' 'to']\n",
            "  Bottom words: ['others' 'novel' 'now' 'nowhere' 'nuclear' 'number' 'obsession' 'off'\n",
            " 'offer' 'old']\n",
            "\n",
            "Genre: Horror\n",
            "  Top words: ['be' 'the' 'you' 'it' 'to' 'die' 'have' 'of' 'evil' 'in']\n",
            "  Bottom words: ['fool' 'period' 'person' 'personal' 'player' 'point' 'pop' 'popularity'\n",
            " 'possibility' 'possible']\n",
            "\n",
            "Genre: Movie\n",
            "  Top words: ['say' 'brown' 'christmas' 'school' 'rock' 'thats' 'other' 'like' 'this'\n",
            " 'no']\n",
            "  Bottom words: ['president' 'promise' 'problem' 'prisoner' 'prison' 'princess' 'price'\n",
            " 'prey' 'pretty' 'proportion']\n",
            "\n",
            "Genre: Music\n",
            "  Top words: ['the' 'be' 'of' 'it' 'you' 'musical' 'love' 'to' 'back' 'in']\n",
            "  Bottom words: ['moon' 'million' 'mile' 'mighty' 'midnight' 'middle' 'michael' 'mess'\n",
            " 'mercy' 'men']\n",
            "\n",
            "Genre: Mystery\n",
            "  Top words: ['be' 'the' 'you' 'of' 'it' 'for' 'to' 'your' 'everything' 'take']\n",
            "  Bottom words: ['twenty' 'hed' 'tradition' 'train' 'travel' 'trip' 'trouble' 'try'\n",
            " 'twelve' 'heaven']\n",
            "\n",
            "Genre: Romance\n",
            "  Top words: ['the' 'love' 'be' 'you' 'to' 'it' 'of' 'in' 'and' 'story']\n",
            "  Bottom words: ['ball' 'assemble' 'assassinate' 'assassin' 'ash' 'belief' 'because'\n",
            " 'totally' 'til' 'number']\n",
            "\n",
            "Genre: Science\n",
            "  Top words: ['the' 'be' 'to' 'it' 'you' 'have' 'of' 'future' 'in' 'begin']\n",
            "  Bottom words: ['half' 'sexual' 'sexy' 'share' 'government' 'grave' 'greatness' 'grow'\n",
            " 'gun' 'sex']\n",
            "\n",
            "Genre: TV\n",
            "  Top words: ['say' 'brown' 'christmas' 'school' 'rock' 'thats' 'other' 'like' 'this'\n",
            " 'no']\n",
            "  Bottom words: ['president' 'promise' 'problem' 'prisoner' 'prison' 'princess' 'price'\n",
            " 'prey' 'pretty' 'proportion']\n",
            "\n",
            "Genre: Thriller\n",
            "  Top words: ['be' 'the' 'you' 'to' 'it' 'of' 'no' 'in' 'have' 'one']\n",
            "  Bottom words: ['zero' 'aint' 'writer' 'write' 'romantic' 'ruin' 'amazing' 'americas'\n",
            " 'winner' 'wonderful']\n",
            "\n",
            "Genre: War\n",
            "  Top words: ['the' 'be' 'of' 'to' 'war' 'man' 'for' 'his' 'in' 'and']\n",
            "  Bottom words: ['partner' 'ours' 'outlaw' 'outside' 'over' 'oz' 'page' 'pain' 'paradise'\n",
            " 'paranoia']\n",
            "\n",
            "Genre: Western\n",
            "  Top words: ['the' 'be' 'of' 'man' 'and' 'to' 'in' 'never' 'who' 'you']\n",
            "  Bottom words: ['name' 'moment' 'mom' 'modern' 'mission' 'miss' 'miracle' 'minute'\n",
            " 'million' 'mile']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f0bec87",
        "outputId": "5ca67225-d654-4f39-d24c-6a3c98579e62"
      },
      "source": [
        "print(\"\\n--- Genre Word Analysis for Keywords ---\\n\")\n",
        "keywords_genre_analysis = genre_word_analysis(df, \"keywords\")\n",
        "for genre, data in keywords_genre_analysis.items():\n",
        "    print(f\"Genre: {genre}\")\n",
        "    print(f\"  Top words: {data['top_words']}\")\n",
        "    print(f\"  Bottom words: {data['bottom_words']}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Genre Word Analysis for Keywords ---\n",
            "\n",
            "Genre: Action\n",
            "  Top words: ['dystopia' 'comic' 'on' 'war' 'base' 'secret' 'of' 'art' 'martial'\n",
            " 'assassin']\n",
            "  Bottom words: ['kennedy' 'orleans' 'onenight' 'old' 'ohio' 'occult' 'immigrant'\n",
            " 'imaginary' 'daydream' 'day']\n",
            "\n",
            "Genre: Adventure\n",
            "  Top words: ['on' 'base' 'comic' 'of' 'england' 'secret' 'magic' 'the' 'alien' 'novel']\n",
            "  Bottom words: ['last' 'dress' 'dominatrix' 'domestic' 'kennedy' 'leave' 'leader' 'lead'\n",
            " 'laxative' 'law']\n",
            "\n",
            "Genre: Animation\n",
            "  Top words: ['animation' 'magic' 'alien' 'musical' 'relationship' 'animal' 'father'\n",
            " 'duringcreditsstinger' 'aftercreditsstinger' 'on']\n",
            "  Bottom words: ['newspaper' 'nun' 'number' 'nudity' 'nuclear' 'northern' 'north' 'noise'\n",
            " 'nixon' 'ninja']\n",
            "\n",
            "Genre: Comedy\n",
            "  Top words: ['film' 'independent' 'relationship' 'duringcreditsstinger' 'love' 'woman'\n",
            " 'comedy' 'new' 'sex' 'director']\n",
            "  Bottom words: ['cinema' 'gladiator' 'survivor' 'survival' 'superhuman' 'rio' 'gift'\n",
            " 'greek' 'graphic' 'civilization']\n",
            "\n",
            "Genre: Crime\n",
            "  Top words: ['drug' 'murder' 'police' 'on' 'fbi' 'prison' 'nudity' 'base' 'new'\n",
            " 'crime']\n",
            "  Bottom words: ['panic' 'fate' 'penguin' 'peasant' 'pearl' 'parentsinlaw' 'fast'\n",
            " 'fashion' 'fascism' 'farm']\n",
            "\n",
            "Genre: Documentary\n",
            "  Top words: ['director' 'woman' 'music' 'corruption' 'usa' 'food' 'comedy' 'film'\n",
            " 'penguin' 'stunt']\n",
            "  Bottom words: ['pennsylvania' 'pig' 'pickpocket' 'photographer' 'phone' 'philosophy'\n",
            " 'philadelphia' 'pet' 'person' 'persia']\n",
            "\n",
            "Genre: Drama\n",
            "  Top words: ['film' 'independent' 'relationship' 'on' 'of' 'base' 'love' 'war' 'novel'\n",
            " 'biography']\n",
            "  Bottom words: ['alternate' 'yoga' 'stupidity' 'asia' 'starfleet' 'dimension' 'dinosaur'\n",
            " 'advertising' 'temple' 'medallion']\n",
            "\n",
            "Genre: Family\n",
            "  Top words: ['duringcreditsstinger' 'base' 'relationship' 'on' 'magic' 'musical'\n",
            " 'novel' 'holiday' 'animal' 'child']\n",
            "  Bottom words: ['groupie' 'psychologist' 'psychological' 'psychic' 'psychiatrist'\n",
            " 'protest' 'protagonist' 'hair' 'hacker' 'guy']\n",
            "\n",
            "Genre: Fantasy\n",
            "  Top words: ['magic' 'base' 'witch' 'on' 'comic' 'vampire' 'novel' 'of' 'relationship'\n",
            " 'fairy']\n",
            "  Bottom words: ['grizzly' 'overdose' 'outlaw' 'outcast' 'ouija' 'pearl' 'patriotism'\n",
            " 'glass' 'girlfriend' 'strike']\n",
            "\n",
            "Genre: Fiction\n",
            "  Top words: ['dystopia' 'alien' 'space' 'comic' 'future' 'time' 'travel' 'the' 'on'\n",
            " 'intelligence']\n",
            "  Bottom words: ['hairdresser' 'greek' 'grief' 'grieve' 'grizzly' 'groupie' 'grow'\n",
            " 'guerrilla' 'guilt' 'guitar']\n",
            "\n",
            "Genre: Foreign\n",
            "  Top words: ['director' 'woman' 'musical' 'hairdresser' 'mobster' 'love' 'tragedy'\n",
            " 'story' 'party' 'dancer']\n",
            "  Bottom words: ['placement' 'poet' 'poem' 'plot' 'playwright' 'playboy' 'play' 'platonic'\n",
            " 'plantation' 'plant']\n",
            "\n",
            "Genre: History\n",
            "  Top words: ['war' 'world' 'ii' 'biography' 'historical' 'figure' 'on' 'base'\n",
            " 'president' 'usa']\n",
            "  Bottom words: ['men' 'mastermind' 'masturbation' 'match' 'matter' 'maze' 'mechanic'\n",
            " 'medallion' 'medical' 'medium']\n",
            "\n",
            "Genre: Horror\n",
            "  Top words: ['vampire' 'murder' 'supernatural' 'zombie' 'nudity' 'slasher' 'remake'\n",
            " 'killer' 'haunt' 'monster']\n",
            "  Bottom words: ['genius' 'paint' 'painter' 'painting' 'palace' 'paleontology' 'pan'\n",
            " 'panda' 'panic' 'paraplegic']\n",
            "\n",
            "Genre: Movie\n",
            "  Top words: ['christmas' 'holiday' 'hurricane' 'tornado' 'school' 'performance'\n",
            " 'beach' 'helicopter' 'california' 'become']\n",
            "  Bottom words: ['pizza' 'poem' 'plot' 'playwright' 'playboy' 'play' 'platonic'\n",
            " 'plantation' 'plant' 'planet']\n",
            "\n",
            "Genre: Music\n",
            "  Top words: ['musical' 'music' 'dance' 'rock' 'woman' 'pop' 'film' 'director' 'singer'\n",
            " 'concert']\n",
            "  Bottom words: ['suspicion' 'teen' 'telekinesis' 'telepathy' 'teleportation' 'surfer'\n",
            " 'surgeon' 'surgery' 'survival' 'survivor']\n",
            "\n",
            "Genre: Mystery\n",
            "  Top words: ['detective' 'on' 'secret' 'murder' 'of' 'base' 'novel' 'film'\n",
            " 'investigation' 'suspense']\n",
            "  Bottom words: ['humor' 'swordplay' 'hobbit' 'hockey' 'holdup' 'hole' 'holiday'\n",
            " 'hollywood' 'holocaust' 'homeless']\n",
            "\n",
            "Genre: Romance\n",
            "  Top words: ['love' 'film' 'woman' 'independent' 'relationship' 'new' 'of' 'sex'\n",
            " 'director' 'on']\n",
            "  Bottom words: ['matter' 'experimentation' 'exorcism' 'inventor' 'invention' 'menace'\n",
            " 'melt' 'medium' 'medical' 'medallion']\n",
            "\n",
            "Genre: Science\n",
            "  Top words: ['dystopia' 'alien' 'space' 'comic' 'future' 'time' 'travel' 'the' 'on'\n",
            " 'intelligence']\n",
            "  Bottom words: ['hairdresser' 'greek' 'grief' 'grieve' 'grizzly' 'groupie' 'grow'\n",
            " 'guerrilla' 'guilt' 'guitar']\n",
            "\n",
            "Genre: TV\n",
            "  Top words: ['christmas' 'holiday' 'hurricane' 'tornado' 'school' 'performance'\n",
            " 'beach' 'helicopter' 'california' 'become']\n",
            "  Bottom words: ['pizza' 'poem' 'plot' 'playwright' 'playboy' 'play' 'platonic'\n",
            " 'plantation' 'plant' 'planet']\n",
            "\n",
            "Genre: Thriller\n",
            "  Top words: ['murder' 'on' 'secret' 'of' 'base' 'nudity' 'dystopia' 'police' 'novel'\n",
            " 'england']\n",
            "  Bottom words: ['kindergarten' 'nelson' 'slacker' 'fame' 'familys' 'fashion' 'fast'\n",
            " 'fate' 'favorite' 'fear']\n",
            "\n",
            "Genre: War\n",
            "  Top words: ['war' 'world' 'ii' 'army' 'of' 'vietnam' 'soldier' 'veteran' 'base' 'on']\n",
            "  Bottom words: ['muppets' 'nelson' 'news' 'newspaper' 'night' 'nightclub' 'nightmare'\n",
            " 'mountain' 'mouse' 'movie']\n",
            "\n",
            "Genre: Western\n",
            "  Top words: ['gunslinger' 'horse' 'sheriff' 'bounty' 'hunter' 'texas' 'ranger'\n",
            " 'showdown' 'marshal' 'gun']\n",
            "  Bottom words: ['parent' 'pennsylvania' 'penguin' 'peasant' 'pearl' 'patriotism' 'pastor'\n",
            " 'past' 'part' 'parody']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "def genre_indicative_words(df, text_col, top_k=10):\n",
        "    tfidf = TfidfVectorizer(min_df=3)\n",
        "    X = tfidf.fit_transform(df[text_col])\n",
        "    vocab = np.array(tfidf.get_feature_names_out())\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for genre in mlb.classes_:\n",
        "        # Binary labels for one-vs-rest\n",
        "        y = df[\"genres\"].apply(lambda x: genre in x).astype(int)\n",
        "\n",
        "        clf = LogisticRegression(max_iter=1000)\n",
        "        clf.fit(X, y)\n",
        "\n",
        "        # Coefficients\n",
        "        coef = clf.coef_[0]\n",
        "\n",
        "        top_indices = np.argsort(coef)[-top_k:]\n",
        "        top_words = vocab[top_indices]\n",
        "\n",
        "        results[genre] = top_words\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "tadJXjIw-S--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Genre-Indicative Words Using TF-IDF ---\\n\")\n",
        "indicative_results = genre_indicative_words(df, \"overview\")\n",
        "\n",
        "for genre, words in indicative_results.items():\n",
        "    print(f\"Genre: {genre}\")\n",
        "    print(\"  Indicative words:\", words)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO4ABSQ5-fif",
        "outputId": "ebb3eac4-a5c3-4388-ae36-5d201160139c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Genre-Indicative Words Using TF-IDF ---\n",
            "\n",
            "Genre: Action\n",
            "  Indicative words: ['warrior' 'hero' 'cia' 'criminal' 'the' 'target' 'battle' 'assassin'\n",
            " 'cop' 'agent']\n",
            "\n",
            "Genre: Adventure\n",
            "  Indicative words: ['dinosaur' 'destroy' 'find' 'warrior' 'mission' 'power' 'world' 'the'\n",
            " 'bond' 'adventure']\n",
            "\n",
            "Genre: Animation\n",
            "  Indicative words: ['accidentally' 'dream' 'dinosaur' 'shrek' 'when' 'and' 'human' 'penguin'\n",
            " 'world' 'adventure']\n",
            "\n",
            "Genre: Comedy\n",
            "  Indicative words: ['doesnt' 'wedding' 'christmas' 'date' 'big' 'all' 'show' 'guy' 'up'\n",
            " 'comedy']\n",
            "\n",
            "Genre: Crime\n",
            "  Indicative words: ['mob' 'killer' 'mafia' 'fbi' 'criminal' 'cop' 'drug' 'detective' 'police'\n",
            " 'murder']\n",
            "\n",
            "Genre: Documentary\n",
            "  Indicative words: ['of' 'me' 'michael' 'filmmaker' 'interview' 'and' 'footage' 'film' 'the'\n",
            " 'documentary']\n",
            "\n",
            "Genre: Drama\n",
            "  Indicative words: ['family' 'her' 'change' 'rise' 'his' 'drama' 'love' 'wife' 'life' 'story']\n",
            "\n",
            "Genre: Family\n",
            "  Indicative words: ['animal' 'christmas' 'name' 'up' 'world' 'save' 'land' 'boy' 'dog'\n",
            " 'adventure']\n",
            "\n",
            "Genre: Fantasy\n",
            "  Indicative words: ['magic' 'magical' 'save' 'witch' 'dragon' 'ancient' 'power' 'king'\n",
            " 'vampire' 'evil']\n",
            "\n",
            "Genre: Fiction\n",
            "  Indicative words: ['time' 'power' 'space' 'robot' 'scientist' 'human' 'future' 'planet'\n",
            " 'earth' 'alien']\n",
            "\n",
            "Genre: Foreign\n",
            "  Indicative words: ['religious' 'dance' 'tire' 'onto' 'riot' 'disappears' 'crawford' 'with'\n",
            " 'detroit' 'film']\n",
            "\n",
            "Genre: History\n",
            "  Indicative words: ['american' 'true' 'ii' 'british' 'army' 'in' 'story' 'of' 'war' 'the']\n",
            "\n",
            "Genre: Horror\n",
            "  Indicative words: ['terrorize' 'mysterious' 'strange' 'horrific' 'killer' 'creature' 'group'\n",
            " 'horror' 'zombie' 'vampire']\n",
            "\n",
            "Genre: Movie\n",
            "  Indicative words: ['everyone' 'tornado' 'hurricane' 'scoop' 'claudia' 'maneating'\n",
            " 'sharkinfested' 'charlie' 'brown' 'christmas']\n",
            "\n",
            "Genre: Music\n",
            "  Indicative words: ['and' 'show' 'dance' 'dream' 'rock' 'dancer' 'musical' 'band' 'music'\n",
            " 'singer']\n",
            "\n",
            "Genre: Mystery\n",
            "  Indicative words: ['that' 'killer' 'investigation' 'mystery' 'mysterious' 'disappearance'\n",
            " 'clue' 'suspect' 'detective' 'murder']\n",
            "\n",
            "Genre: Romance\n",
            "  Indicative words: ['date' 'her' 'romantic' 'relationship' 'lover' 'woman' 'fall' 'romance'\n",
            " 'meet' 'love']\n",
            "\n",
            "Genre: Science\n",
            "  Indicative words: ['time' 'power' 'space' 'robot' 'scientist' 'human' 'future' 'planet'\n",
            " 'earth' 'alien']\n",
            "\n",
            "Genre: TV\n",
            "  Indicative words: ['everyone' 'tornado' 'hurricane' 'scoop' 'claudia' 'maneating'\n",
            " 'sharkinfested' 'charlie' 'brown' 'christmas']\n",
            "\n",
            "Genre: Thriller\n",
            "  Indicative words: ['assassin' 'terrorist' 'secret' 'officer' 'target' 'bond' 'cia' 'agent'\n",
            " 'killer' 'murder']\n",
            "\n",
            "Genre: War\n",
            "  Indicative words: ['fight' 'american' 'mission' 'the' 'vietnam' 'soldier' 'ii' 'army'\n",
            " 'during' 'war']\n",
            "\n",
            "Genre: Western\n",
            "  Indicative words: ['bandit' 'notorious' 'western' 'the' 'civil' 'sheriff' 'gang' 'town'\n",
            " 'west' 'outlaw']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Genre-Indicative Words Using TF-IDF ---\\n\")\n",
        "indicative_results = genre_indicative_words(df, \"tagline\")\n",
        "\n",
        "for genre, words in indicative_results.items():\n",
        "    print(f\"Genre: {genre}\")\n",
        "    print(\"  Indicative words:\", words)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsHMbeNW-knH",
        "outputId": "49783ba9-b669-43d1-80bf-50e581643a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Genre-Indicative Words Using TF-IDF ---\n",
            "\n",
            "Genre: Action\n",
            "  Indicative words: ['mission' 'enemy' 'bond' 'beginning' 'protect' 'kill' 'action'\n",
            " 'vengeance' 'hero' 'cop']\n",
            "\n",
            "Genre: Adventure\n",
            "  Indicative words: ['earth' 'james' 'danger' 'bear' 'wild' 'legend' 'bond' 'beginning' 'hero'\n",
            " 'adventure']\n",
            "\n",
            "Genre: Animation\n",
            "  Indicative words: ['save' 'season' 'great' 'grave' 'tale' 'toy' 'fairy' 'wish' 'little'\n",
            " 'adventure']\n",
            "\n",
            "Genre: Comedy\n",
            "  Indicative words: ['big' 'movie' 'hit' 'put' 'funny' 'little' 'shes' 'party' 'get' 'comedy']\n",
            "\n",
            "Genre: Crime\n",
            "  Indicative words: ['clean' 'money' 'cop' 'murder' 'sin' 'killer' 'deadly' 'criminal' 'law'\n",
            " 'crime']\n",
            "\n",
            "Genre: Documentary\n",
            "  Indicative words: ['day' 'of' 'on' 'foot' 'up' 'home' 'in' 'at' 'what' 'film']\n",
            "\n",
            "Genre: Drama\n",
            "  Indicative words: ['shot' 'hope' 'sometimes' 'dream' 'how' 'honor' 'love' 'she' 'story'\n",
            " 'life']\n",
            "\n",
            "Genre: Family\n",
            "  Indicative words: ['summer' 'wish' 'world' 'toy' 'neighborhood' 'friend' 'proportion'\n",
            " 'jungle' 'little' 'adventure']\n",
            "\n",
            "Genre: Fantasy\n",
            "  Indicative words: ['world' 'animal' 'beyond' 'beginning' 'hell' 'classic' 'wish' 'afterlife'\n",
            " 'believe' 'darkness']\n",
            "\n",
            "Genre: Fiction\n",
            "  Indicative words: ['alien' 'kill' 'begin' 'our' 'not' 'universe' 'planet' 'space' 'earth'\n",
            " 'future']\n",
            "\n",
            "Genre: Foreign\n",
            "  Indicative words: ['brother' 'bitter' 'temptation' 'both' 'call' 'promise' 'paradise' 'he'\n",
            " 'father' 'conquer']\n",
            "\n",
            "Genre: History\n",
            "  Indicative words: ['motion' 'great' 'men' 'change' 'picture' 'true' 'incredible' 'nation'\n",
            " 'world' 'man']\n",
            "\n",
            "Genre: Horror\n",
            "  Indicative words: ['scream' 'alive' 'night' 'hell' 'fear' 'dead' 'evil' 'horror' 'die'\n",
            " 'terror']\n",
            "\n",
            "Genre: Movie\n",
            "  Indicative words: ['about' 'this' 'like' 'other' 'thats' 'rock' 'school' 'christmas' 'brown'\n",
            " 'say']\n",
            "\n",
            "Genre: Music\n",
            "  Indicative words: ['back' 'holiday' 'youve' 'picture' 'give' 'motion' 'dont' 'dance' 'rock'\n",
            " 'musical']\n",
            "\n",
            "Genre: Mystery\n",
            "  Indicative words: ['john' 'evil' 'perfect' 'killer' 'take' 'everything' 'truth' 'lie' 'far'\n",
            " 'murder']\n",
            "\n",
            "Genre: Romance\n",
            "  Indicative words: ['then' 'right' 'seduction' 'she' 'comedy' 'heart' 'date' 'woman'\n",
            " 'romance' 'love']\n",
            "\n",
            "Genre: Science\n",
            "  Indicative words: ['alien' 'kill' 'begin' 'our' 'not' 'universe' 'planet' 'space' 'earth'\n",
            " 'future']\n",
            "\n",
            "Genre: TV\n",
            "  Indicative words: ['about' 'this' 'like' 'other' 'thats' 'rock' 'school' 'christmas' 'brown'\n",
            " 'say']\n",
            "\n",
            "Genre: Thriller\n",
            "  Indicative words: ['case' 'horror' 'now' 'afraid' 'sin' 'bond' 'fear' 'kill' 'murder'\n",
            " 'killer']\n",
            "\n",
            "Genre: War\n",
            "  Indicative words: ['incredible' 'nation' 'history' 'innocence' 'man' 'honor' 'their' 'fight'\n",
            " 'glory' 'war']\n",
            "\n",
            "Genre: Western\n",
            "  Indicative words: ['forget' 'never' 'hell' 'passion' 'legend' 'who' 'hero' 'reason' 'west'\n",
            " 'man']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Genre-Indicative Words Using TF-IDF ---\\n\")\n",
        "indicative_results = genre_indicative_words(df, \"keywords\")\n",
        "\n",
        "for genre, words in indicative_results.items():\n",
        "    print(f\"Genre: {genre}\")\n",
        "    print(\"  Indicative words:\", words)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzwJj5MA-lJ7",
        "outputId": "2eff9485-c916-4e8c-a944-b1d07197caae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Genre-Indicative Words Using TF-IDF ---\n",
            "\n",
            "Genre: Action\n",
            "  Indicative words: ['cop' 'marvel' 'disaster' 'agent' 'helicopter' 'hero' 'dystopia'\n",
            " 'assassin' 'martial' 'comic']\n",
            "\n",
            "Genre: Adventure\n",
            "  Indicative words: ['england' 'egypt' 'hero' 'ocean' 'adventure' 'liberation' 'treasure'\n",
            " 'comic' 'magic' 'marvel']\n",
            "\n",
            "Genre: Animation\n",
            "  Indicative words: ['fish' 'stop' 'alien' 'animal' 'sea' 'bunny' 'penguin' 'magic' 'bird'\n",
            " 'animation']\n",
            "\n",
            "Genre: Comedy\n",
            "  Indicative words: ['birth' 'aftercreditsstinger' 'dog' 'date' 'high' 'christmas' 'holiday'\n",
            " 'friendship' 'spoof' 'comedy']\n",
            "\n",
            "Genre: Crime\n",
            "  Indicative words: ['agent' 'hitman' 'undercover' 'prison' 'detective' 'crime' 'murder'\n",
            " 'drug' 'fbi' 'police']\n",
            "\n",
            "Genre: Documentary\n",
            "  Indicative words: ['pain' 'stuntman' 'concert' 'usa' 'stunt' 'penguin' 'corruption' 'food'\n",
            " 'director' 'music']\n",
            "\n",
            "Genre: Drama\n",
            "  Indicative words: ['novel' 'obsession' 'individual' 'depression' 'love' 'suicide' 'adultery'\n",
            " 'rape' 'war' 'biography']\n",
            "\n",
            "Genre: Family\n",
            "  Indicative words: ['musical' 'wretch' 'bird' 'bear' 'child' 'animal' 'dog' 'holiday'\n",
            " 'animation' 'magic']\n",
            "\n",
            "Genre: Fantasy\n",
            "  Indicative words: ['fairy' 'immortality' 'monster' 'comic' 'dragon' 'adventure' 'fantasy'\n",
            " 'vampire' 'witch' 'magic']\n",
            "\n",
            "Genre: Fiction\n",
            "  Indicative words: ['comic' 'mutant' 'android' 'robot' 'superhero' 'time' 'future' 'space'\n",
            " 'alien' 'dystopia']\n",
            "\n",
            "Genre: Foreign\n",
            "  Indicative words: ['indian' 'dancer' 'party' 'story' 'tragedy' 'woman' 'director' 'musical'\n",
            " 'mobster' 'hairdresser']\n",
            "\n",
            "Genre: History\n",
            "  Indicative words: ['battlefield' 'egypt' 'assassination' 'biography' 'figure' 'epic' 'world'\n",
            " 'ii' 'historical' 'war']\n",
            "\n",
            "Genre: Horror\n",
            "  Indicative words: ['exorcism' 'mutant' 'monster' 'haunt' 'nightmare' 'slasher' 'remake'\n",
            " 'supernatural' 'zombie' 'vampire']\n",
            "\n",
            "Genre: Movie\n",
            "  Indicative words: ['become' 'california' 'helicopter' 'beach' 'performance' 'school'\n",
            " 'tornado' 'hurricane' 'holiday' 'christmas']\n",
            "\n",
            "Genre: Music\n",
            "  Indicative words: ['country' 'star' 'ballet' 'pop' 'concert' 'singer' 'rock' 'dance' 'music'\n",
            " 'musical']\n",
            "\n",
            "Genre: Mystery\n",
            "  Indicative words: ['private' 'suspense' 'nightmare' 'technology' 'obsession' 'secret'\n",
            " 'amnesia' 'hallucination' 'investigation' 'detective']\n",
            "\n",
            "Genre: Romance\n",
            "  Indicative words: ['woman' 'single' 'architect' 'virgin' 'sex' 'bollywood' 'marriage'\n",
            " 'romantic' 'lovesickness' 'love']\n",
            "\n",
            "Genre: Science\n",
            "  Indicative words: ['comic' 'mutant' 'android' 'robot' 'superhero' 'time' 'future' 'space'\n",
            " 'alien' 'dystopia']\n",
            "\n",
            "Genre: TV\n",
            "  Indicative words: ['become' 'california' 'helicopter' 'beach' 'performance' 'school'\n",
            " 'tornado' 'hurricane' 'holiday' 'christmas']\n",
            "\n",
            "Genre: Thriller\n",
            "  Indicative words: ['assassin' 'detective' 'obsession' 'nightmare' 'killer' 'kidnap'\n",
            " 'assassination' 'hostage' 'revenge' 'psychopath']\n",
            "\n",
            "Genre: War\n",
            "  Indicative words: ['general' 'resistance' 'pilot' 'veteran' 'soldier' 'vietnam' 'world'\n",
            " 'army' 'ii' 'war']\n",
            "\n",
            "Genre: Western\n",
            "  Indicative words: ['native' 'showdown' 'marshal' 'texas' 'hunter' 'ranger' 'bounty'\n",
            " 'sheriff' 'horse' 'gunslinger']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}